{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"QcCmxsI2l5VU"},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\n","import os, types\n","import pandas as pd\n","from botocore.client import Config\n","import ibm_boto3\n","\n","def __iter__(self): return 0\n","\n","# @hidden_cell\n","# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n","# You might want to remove those credentials before you share the notebook.\n","cos_client = ibm_boto3.client(service_name='s3',\n","    ibm_api_key_id='PsRxZWijDRPuYfAUghaSALVzvm9UNoNs6llpbk5q3y8i',\n","    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n","    config=Config(signature_version='oauth'),\n","    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n","\n","bucket = 'gestureidentification-donotdelete-pr-bpwz2af7ki1ztl'\n","object_key = 'Dataset-20221112T112148Z-001.zip'\n","\n","streaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n","\n","# Your data file was loaded into a botocore.response.StreamingBody object.\n","# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n","# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n","# pandas documentation: http://pandas.pydata.org/\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from io import BytesIO\n","import zipfile\n","unzip = zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\n","filepaths = unzip.namelist()\n","for path in filepaths:\n","    unzip.extract(path)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"WzY9W6V1mGFT"},"outputs":[],"source":["train_datagen = ImageDataGenerator(rescale=1.0/255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8CbBRJi0oz-q","outputId":"5549bc02-feec-4543-afbb-6a7051701355"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 594 images belonging to 6 classes.\n","Found 30 images belonging to 6 classes.\n"]}],"source":["X_train = train_datagen.flow_from_directory('Dataset/train',target_size=(64,64),batch_size=32,class_mode = 'categorical',color_mode='grayscale')\n","x_test = train_datagen.flow_from_directory('Dataset/test',target_size=(64,64),batch_size=32,class_mode = 'categorical',color_mode='grayscale')"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Cw-8aPUmpcoq"},"outputs":[],"source":["#model building\n","import numpy as np\n","import tensorflow\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D\n","classifier = Sequential()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVHOjkVtqlxJ","outputId":"0b844f01-ae76-4738-ec12-90176d3c6b16"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 62, 62, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 6272)              0         \n","                                                                 \n"," dense (Dense)               (None, 128)               802944    \n","                                                                 \n"," dense_1 (Dense)             (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 813,286\n","Trainable params: 813,286\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["classifier.add(Conv2D(32,(3,3),input_shape =(64,64,1),activation='relu'))\n","classifier.add(MaxPooling2D(pool_size=(2,2)))\n","classifier.add(Conv2D(32,(3,3),activation='relu'))\n","classifier.add(MaxPooling2D(pool_size=(2,2)))\n","classifier.add(Flatten())\n","classifier.add(Dense(units=128,activation='relu'))\n","classifier.add(Dense(units=6,activation='softmax'))\n","classifier.summary()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"tefzpAnHrzZc"},"outputs":[],"source":["classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CqOo1FABtd2l","outputId":"3c3bc14b-4b65-45e0-cc64-3fccbb392f03"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/wsuser/ipykernel_164/1477240979.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  classifier.fit_generator(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","19/19 [==============================] - 4s 161ms/step - loss: 1.7552 - accuracy: 0.2626 - val_loss: 1.6149 - val_accuracy: 0.3333\n","Epoch 2/20\n","19/19 [==============================] - 3s 160ms/step - loss: 1.3032 - accuracy: 0.5589 - val_loss: 1.0376 - val_accuracy: 0.5333\n","Epoch 3/20\n","19/19 [==============================] - 3s 144ms/step - loss: 0.8389 - accuracy: 0.6919 - val_loss: 0.8143 - val_accuracy: 0.6667\n","Epoch 4/20\n","19/19 [==============================] - 3s 145ms/step - loss: 0.6669 - accuracy: 0.7104 - val_loss: 0.5315 - val_accuracy: 0.8667\n","Epoch 5/20\n","19/19 [==============================] - 3s 146ms/step - loss: 0.5509 - accuracy: 0.7694 - val_loss: 0.4404 - val_accuracy: 0.9000\n","Epoch 6/20\n","19/19 [==============================] - 3s 146ms/step - loss: 0.4436 - accuracy: 0.8148 - val_loss: 0.5756 - val_accuracy: 0.8000\n","Epoch 7/20\n","19/19 [==============================] - 3s 151ms/step - loss: 0.4051 - accuracy: 0.8367 - val_loss: 0.4291 - val_accuracy: 0.9000\n","Epoch 8/20\n","19/19 [==============================] - 3s 153ms/step - loss: 0.3310 - accuracy: 0.8855 - val_loss: 0.4783 - val_accuracy: 0.8000\n","Epoch 9/20\n","19/19 [==============================] - 3s 136ms/step - loss: 0.2862 - accuracy: 0.8956 - val_loss: 0.3016 - val_accuracy: 0.9667\n","Epoch 10/20\n","19/19 [==============================] - 3s 149ms/step - loss: 0.2673 - accuracy: 0.9175 - val_loss: 0.4154 - val_accuracy: 0.9000\n","Epoch 11/20\n","19/19 [==============================] - 3s 153ms/step - loss: 0.2432 - accuracy: 0.9125 - val_loss: 0.3356 - val_accuracy: 0.8333\n","Epoch 12/20\n","19/19 [==============================] - 3s 145ms/step - loss: 0.1884 - accuracy: 0.9461 - val_loss: 0.2535 - val_accuracy: 0.9333\n","Epoch 13/20\n","19/19 [==============================] - 3s 138ms/step - loss: 0.1669 - accuracy: 0.9545 - val_loss: 0.2384 - val_accuracy: 0.9667\n","Epoch 14/20\n","19/19 [==============================] - 3s 158ms/step - loss: 0.1725 - accuracy: 0.9461 - val_loss: 0.3563 - val_accuracy: 0.9000\n","Epoch 15/20\n","19/19 [==============================] - 3s 153ms/step - loss: 0.1491 - accuracy: 0.9579 - val_loss: 0.2386 - val_accuracy: 0.9333\n","Epoch 16/20\n","19/19 [==============================] - 3s 154ms/step - loss: 0.1564 - accuracy: 0.9394 - val_loss: 0.3432 - val_accuracy: 0.9000\n","Epoch 17/20\n","19/19 [==============================] - 3s 148ms/step - loss: 0.1415 - accuracy: 0.9461 - val_loss: 0.2549 - val_accuracy: 0.9667\n","Epoch 18/20\n","19/19 [==============================] - 3s 141ms/step - loss: 0.1445 - accuracy: 0.9579 - val_loss: 0.2120 - val_accuracy: 0.9667\n","Epoch 19/20\n","19/19 [==============================] - 3s 153ms/step - loss: 0.1163 - accuracy: 0.9646 - val_loss: 0.1446 - val_accuracy: 0.9667\n","Epoch 20/20\n","19/19 [==============================] - 3s 171ms/step - loss: 0.1146 - accuracy: 0.9579 - val_loss: 0.2820 - val_accuracy: 0.9000\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f5fb2034a30>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["classifier.fit_generator(\n","    generator=X_train,steps_per_epoch=len(X_train),\n","    epochs=20,validation_data=x_test,validation_steps=len(x_test)\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"rB3JmAVpuLnC"},"outputs":[],"source":["classifier.save('gesture.h5')\n","model_json=classifier.to_json()\n","with open(\"model-bw.json\",'w')as json_file:\n","  json_file.write(model_json)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!tar -zcvf model.tgz gesture.h5"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"SHbk2sZZxHMg"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","from tensorflow.keras.utils import load_img,img_to_array\n","model = load_model(\"gesture.h5\")"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"36P2jn6xw2Mf","outputId":"3f273205-f699-4cb8-b7f3-251f16f6dc9c"},"outputs":[{"data":{"text/plain":["array([[0., 0., 1., 0., 0., 0.]], dtype=float32)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["img = load_img('/content/drive/MyDrive/IBM/test/2/1.jpg',grayscale=True,\n","                     target_size=(64,64))\n","x = img_to_array(img)\n","x = np.expand_dims(x,axis=0)\n","pred = model.predict(x)\n","pred"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["from ibm_watson_machine_learning import APIClient\n","wml_credentials ={\n","        \"url\":\"https://us-south.ml.cloud.ibm.com\",\n","        \"apikey\":\"o9dTlYeIrolX2yzbm3pD1eNKu--FJXoZmgl4alDutFkq\"\n","    }\n","client = APIClient(wml_credentials)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def guid_from_space_name(client,space_name):\n","    space=client.spaces.get_details()\n","    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["05ca3c80-b748-421b-8fae-010bef086c0a\n"]}],"source":["space_uid = guid_from_space_name(client,'gestureidentification')\n","print(space_uid)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["'SUCCESS'"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["client.set.default_space(space_uid)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["'acd9c798-6974-5d2f-a657-ce06e986df4d'"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["software_spec_uid = client.software_specifications.get_uid_by_name(\"tensorflow_rt22.1-py3.9\")\n","software_spec_uid"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["'faeb0c29-65a4-4bf8-854b-388f14e02613'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["model_details=client.repository.store_model(model='model.tgz',meta_props={\n","    client.repository.ModelMetaNames.NAME:'CNN',\n","    client.repository.ModelMetaNames.TYPE:\"tensorflow_2.7\",\n","    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid\n","})\n","model_id = client.repository.get_model_id(model_details)\n","model_id"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully saved model content to file: 'my_model.tar.gz'\n"]},{"data":{"text/plain":["'/home/wsuser/work/my_model.tar.gz'"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["client.repository.download(model_id,'my_model.tar.gz')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":1}
